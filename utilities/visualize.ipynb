{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "'''VGG16 model for Keras.\n",
    "\n",
    "# Reference:\n",
    "\n",
    "- [Very Deep Convolutional Networks for Large-Scale Image Recognition](https://arxiv.org/abs/1409.1556)\n",
    "\n",
    "'''\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Flatten, Dense, Input\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.preprocessing import image\n",
    "from keras.utils.layer_utils import convert_all_kernels_in_model\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras import backend as K\n",
    "from imagenet_utils import decode_predictions, preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TH_WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_th_dim_ordering_th_kernels.h5'\n",
    "TF_WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5'\n",
    "TH_WEIGHTS_PATH_NO_TOP = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_th_dim_ordering_th_kernels_notop.h5'\n",
    "TF_WEIGHTS_PATH_NO_TOP = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "\n",
    "\n",
    "def VGG16(include_top=True, weights='imagenet',\n",
    "          input_tensor=None):\n",
    "    '''Instantiate the VGG16 architecture,\n",
    "    optionally loading weights pre-trained\n",
    "    on ImageNet. Note that when using TensorFlow,\n",
    "    for best performance you should set\n",
    "    `image_dim_ordering=\"tf\"` in your Keras config\n",
    "    at ~/.keras/keras.json.\n",
    "\n",
    "    The model and the weights are compatible with both\n",
    "    TensorFlow and Theano. The dimension ordering\n",
    "    convention used by the model is the one\n",
    "    specified in your Keras config file.\n",
    "\n",
    "    # Arguments\n",
    "        include_top: whether to include the 3 fully-connected\n",
    "            layers at the top of the network.\n",
    "        weights: one of `None` (random initialization)\n",
    "            or \"imagenet\" (pre-training on ImageNet).\n",
    "        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n",
    "            to use as image input for the model.\n",
    "\n",
    "    # Returns\n",
    "        A Keras model instance.\n",
    "    '''\n",
    "    if weights not in {'imagenet', None}:\n",
    "        raise ValueError('The `weights` argument should be either '\n",
    "                         '`None` (random initialization) or `imagenet` '\n",
    "                         '(pre-training on ImageNet).')\n",
    "    # Determine proper input shape\n",
    "    if K.image_dim_ordering() == 'th':\n",
    "        if include_top:\n",
    "            input_shape = (3, 224, 224)\n",
    "        else:\n",
    "            input_shape = (3, None, None)\n",
    "    else:\n",
    "        if include_top:\n",
    "            input_shape = (224, 224, 3)\n",
    "        else:\n",
    "            input_shape = (None, None, 3)\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = Input(shape=input_shape)\n",
    "    else:\n",
    "        if not K.is_keras_tensor(input_tensor):\n",
    "            img_input = Input(tensor=input_tensor)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "    # Block 1\n",
    "    x = Convolution2D(64, 3, 3, activation='relu', border_mode='same', name='block1_conv1')(img_input)\n",
    "    x = Convolution2D(64, 3, 3, activation='relu', border_mode='same', name='block1_conv2')(x)\n",
    "    x1 = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = Convolution2D(128, 3, 3, activation='relu', border_mode='same', name='block2_conv1')(x1)\n",
    "    x = Convolution2D(128, 3, 3, activation='relu', border_mode='same', name='block2_conv2')(x)\n",
    "    x2 = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "\n",
    "    # Block 3\n",
    "    x = Convolution2D(256, 3, 3, activation='relu', border_mode='same', name='block3_conv1')(x2)\n",
    "    x = Convolution2D(256, 3, 3, activation='relu', border_mode='same', name='block3_conv2')(x)\n",
    "    x = Convolution2D(256, 3, 3, activation='relu', border_mode='same', name='block3_conv3')(x)\n",
    "    x3 = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
    "\n",
    "    # Block 4\n",
    "    x = Convolution2D(512, 3, 3, activation='relu', border_mode='same', name='block4_conv1')(x3)\n",
    "    x = Convolution2D(512, 3, 3, activation='relu', border_mode='same', name='block4_conv2')(x)\n",
    "    x = Convolution2D(512, 3, 3, activation='relu', border_mode='same', name='block4_conv3')(x)\n",
    "    x4 = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
    "\n",
    "    # Block 5\n",
    "    x = Convolution2D(512, 3, 3, activation='relu', border_mode='same', name='block5_conv1')(x4)\n",
    "    x = Convolution2D(512, 3, 3, activation='relu', border_mode='same', name='block5_conv2')(x)\n",
    "    x = Convolution2D(512, 3, 3, activation='relu', border_mode='same', name='block5_conv3')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
    "\n",
    "    if include_top:\n",
    "        # Classification block\n",
    "        x = Flatten(name='flatten')(x)\n",
    "        x = Dense(4096, activation='relu', name='fc1')(x)\n",
    "        x = Dense(4096, activation='relu', name='fc2')(x)\n",
    "        x = Dense(1000, activation='softmax', name='predictions')(x)\n",
    "\n",
    "    # Create model\n",
    "    model = Model(img_input, x)\n",
    "\n",
    "    # load weights\n",
    "    if weights == 'imagenet':\n",
    "        print('K.image_dim_ordering:', K.image_dim_ordering())\n",
    "        if K.image_dim_ordering() == 'th':\n",
    "            if include_top:\n",
    "                weights_path = get_file('vgg16_weights_th_dim_ordering_th_kernels.h5',\n",
    "                                        TH_WEIGHTS_PATH,\n",
    "                                        cache_subdir='models')\n",
    "            else:\n",
    "                weights_path = get_file('vgg16_weights_th_dim_ordering_th_kernels_notop.h5',\n",
    "                                        TH_WEIGHTS_PATH_NO_TOP,\n",
    "                                        cache_subdir='models')\n",
    "            model.load_weights(weights_path, by_name=True)\n",
    "            if K.backend() == 'tensorflow':\n",
    "                warnings.warn('You are using the TensorFlow backend, yet you '\n",
    "                              'are using the Theano '\n",
    "                              'image dimension ordering convention '\n",
    "                              '(`image_dim_ordering=\"th\"`). '\n",
    "                              'For best performance, set '\n",
    "                              '`image_dim_ordering=\"tf\"` in '\n",
    "                              'your Keras config '\n",
    "                              'at ~/.keras/keras.json.')\n",
    "                convert_all_kernels_in_model(model)\n",
    "        else:\n",
    "            if include_top:\n",
    "                weights_path = get_file('vgg16_weights_tf_dim_ordering_tf_kernels.h5',\n",
    "                                        TF_WEIGHTS_PATH,\n",
    "                                        cache_subdir='models')\n",
    "            else:\n",
    "                weights_path = get_file('vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "                                        TF_WEIGHTS_PATH_NO_TOP,\n",
    "                                        cache_subdir='models')\n",
    "            model.load_weights(weights_path, by_name=True)\n",
    "            if K.backend() == 'theano':\n",
    "                convert_all_kernels_in_model(model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K.image_dim_ordering: th\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:107: UserWarning: You are using the TensorFlow backend, yet you are using the Theano image dimension ordering convention (`image_dim_ordering=\"th\"`). For best performance, set `image_dim_ordering=\"tf\"` in your Keras config at ~/.keras/keras.json.\n"
     ]
    }
   ],
   "source": [
    "model = VGG16(include_top=False, weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 224, 224)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input image shape: (1, 3, 224, 224)\n"
     ]
    }
   ],
   "source": [
    "img_path = 'dm6_c.png'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "print('Input image shape:', x.shape)\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with a Sequential model\n",
    "get_3rd_layer_output = K.function([model.layers[0].input],\n",
    "                                  [model.layers[3].output])\n",
    "preds = get_3rd_layer_output([x])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/dist-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# %matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 64, 112, 112)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(np.squeeze(preds[0,8,:,:]), cmap='Greys_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n"
     ]
    }
   ],
   "source": [
    "%matplotlib auto\n",
    "r = 8\n",
    "c = 8\n",
    "f, axarr = plt.subplots(r,c)\n",
    "\n",
    "# plotting input image\n",
    "for i in range(r):\n",
    "    for j in range(c):\n",
    "       axarr[i,j].imshow(np.squeeze(preds[0,i*c+j,:,:]))#, cmap='Greys_r')\n",
    "       axarr[i,j].set_axis_off()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.topology.InputLayer at 0x7f9eae7f3cd0>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x7f9eae7f3410>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x7f9eae722c10>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x7f9eae6e7a50>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x7f9eae72bb50>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x7f9eae6dca50>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x7f9eae6ad550>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x7f9eae669410>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x7f9eae609e90>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x7f9eae5f7a50>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x7f9eae5a9910>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x7f9eae572e50>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x7f9eae559850>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x7f9eae4c45d0>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x7f9eae44e3d0>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x7f9eae45bd90>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x7f9eae471a10>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x7f9eae4158d0>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x7f9eae3cad90>]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
